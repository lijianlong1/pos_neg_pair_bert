# Coding by long
# Datatime:2021/12/19 10:48
# Filename:dataread_test.py
# Toolby: PyCharm
# ______________coding_____________
#import numpy as np
# import torch
# from transformers import BertTokenizer
# from traincode.models import BERT_Model_Classfy
# bert_path = '../bertmodel/bert-base-uncased'
# model = BERT_Model_Classfy(bertmodelpath=bert_path)
# tokenizer = BertTokenizer.from_pretrained(bert_path)
# input = tokenizer.encode('hee few fwe jofi', add_special_tokens=True)
# input_tensor = torch.Tensor(input)
# input_to = input_tensor.reshape(1, -1)
# out = model(input_to.long())
# print(out)
print('这是第：%s次训练过程，训练总时长为%7.2f秒,训练的平均损失值为%f, 测试的损失值为：%f'
              % (str(1), (3.8903240398),1/3, 0.432423))

